"""
è°ƒç”¨ LLMï¼ˆOpenAI/DeepSeek/Qwen ç­‰ï¼‰è§£ç­” 16x16 æ•°ç‹¬é¢˜ç›®çš„è„šæœ¬ã€‚

æµç¨‹ï¼š
1. éšæœºç”Ÿæˆä¸€ä¸ª 16x16 æ•°ç‹¬é¢˜ç›®ï¼ˆæ”¯æŒè‡ªå®šä¹‰æŒ–ç©ºæ•°é‡ï¼‰ã€‚
2. ä¸æ¨¡å‹è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œä¸¥æ ¼ç¦æ­¢ä½¿ç”¨ä»»ä½•å¤–éƒ¨å·¥å…·ã€‚
3. æ¯è½®å›å¤éƒ½ä¼šè§£æã€æ ¡éªŒï¼Œå¹¶æŠŠé—®é¢˜åé¦ˆç»™æ¨¡å‹é‡æ–°ä½œç­”ã€‚
4. æ‰€æœ‰æç¤ºè¯ã€å›å¤ã€æ ¡éªŒç»“æœä¸ï¼ˆè‹¥å­˜åœ¨ï¼‰æ€è€ƒæ‘˜è¦éƒ½ä¼šå†™å…¥ JSON å†å²æ–‡ä»¶ã€‚
"""

from __future__ import annotations

import argparse
import json
import random
import re
import shutil
import time
from pathlib import Path
from typing import Any, List, Optional, Sequence, Tuple

from sudoku16_solver import (
    SIZE,
    Sudoku16Solver,
    board_to_text,
    carve_puzzle,
    generate_complete_board,
)

from llm_client import LLMClientError, PROVIDERS, chat_completion, get_provider

SYSTEM_PROMPT = (
    "You are a reasoning-only assistant working in a plain text environment. "
    "You must not invoke, simulate, or reference any external tools, code execution, "
    "or calculators. Solve the Sudoku puzzle strictly by mental reasoning and provide "
    "your final answer clearly."
)

USER_PROMPT_TEMPLATE = (
    "è¯·åœ¨çº¯æ–‡æœ¬ç¯å¢ƒä¸­è§£ç­”ä¸‹é¢çš„ 16x16 æ•°ç‹¬é¢˜ç›®ã€‚\n"
    "- ç¦æ­¢ä½¿ç”¨ä»»ä½•å¤–éƒ¨å·¥å…·ã€ç¨‹åºæˆ–æ±‚è§£å™¨ï¼Œä¹Ÿä¸è¦å£°ç§°ä½¿ç”¨äº†å·¥å…·ã€‚\n"
    "- è¾“å‡º 16 è¡Œï¼Œæ¯è¡Œ 16 ä¸ªæ•°å­—ï¼ˆèŒƒå›´ 1-16ï¼‰ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†éš”ã€‚\n"
    "- å¦‚æœéœ€è¦è§£é‡Šï¼Œè¯·åœ¨ç­”æ¡ˆä¹‹åé™„åŠ ã€‚\n\n"
    "é¢˜ç›®ï¼š\n{puzzle}\n"
)

FEEDBACK_PROMPT_TEMPLATE = (
    "ä¸Šä¸€è½®ä½ çš„ç­”æ¡ˆå­˜åœ¨é—®é¢˜ï¼Œè¯·åœ¨ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™çš„å‰æä¸‹é‡æ–°è§£ç­”ï¼š\n"
    "- ä»ç„¶ç¦æ­¢ä½¿ç”¨ä»»ä½•å¤–éƒ¨å·¥å…·æˆ–ç¨‹åºï¼Œä¹Ÿä¸è¦å£°ç§°ä½¿ç”¨äº†å·¥å…·ã€‚\n"
    "- è¾“å‡º 16 è¡Œï¼Œæ¯è¡Œ 16 ä¸ªæ•°å­—ï¼ˆèŒƒå›´ 1-16ï¼‰ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†éš”ã€‚\n"
    "- å¿…é¡»ä¿®æ­£åˆ—å‡ºçš„æ‰€æœ‰é—®é¢˜ï¼Œç¡®ä¿ä¸é¢˜é¢ç»™å‡ºçš„å·²çŸ¥æ•°å­—å®Œå…¨ä¸€è‡´ã€‚\n\n"
    "ä¸Šä¸€è½®çš„ç­”æ¡ˆï¼š\n{last_answer}\n\n"
    "å‘ç°çš„é—®é¢˜ï¼š\n{issues}\n\n"
    "è¯·é‡æ–°ç»™å‡ºå®Œæ•´è§£ç­”ã€‚é¢˜ç›®å†æ¬¡æä¾›å¦‚ä¸‹ï¼š\n{puzzle}\n"
)

EXPECTED_SET = set(range(1, SIZE + 1))


def board_to_display_text(board: Sequence[Sequence[int]]) -> str:
    """å±•ç¤ºç”¨æ–‡æœ¬ï¼Œ0 ä½¿ç”¨ '.'ã€‚"""
    return board_to_text(board)


def parse_rows_from_text(text: str, expected: int = SIZE) -> List[List[int]]:
    """
    ä»æ¨¡å‹å›å¤ä¸­æå–æ¯è¡Œçš„ 16 ä¸ªæ•°å­—ã€‚
    æ”¯æŒè¯†åˆ« 0ï¼ˆè§†ä¸ºç•™ç©ºï¼‰ä¸ 1-16ã€‚
    """

    pattern = re.compile(r"\b(?:1[0-6]|[1-9]|0)\b")
    rows: List[List[int]] = []

    for line in text.splitlines():
        values = [int(token) for token in pattern.findall(line)]
        if len(values) == expected:
            rows.append(values)

    return rows


def first_mismatch(
    board_a: Sequence[Sequence[int]],
    board_b: Sequence[Sequence[int]],
) -> Optional[Tuple[int, int]]:
    """è¿”å›ä¸¤ä¸ªæ£‹ç›˜ç¬¬ä¸€ä¸ªä¸åŒçš„åæ ‡ã€‚"""

    for r in range(SIZE):
        for c in range(SIZE):
            if board_a[r][c] != board_b[r][c]:
                return r, c
    return None


# ----------------------------------------------------------------------
# æ ¡éªŒç»“æœ
# ----------------------------------------------------------------------
class SudokuCheckResult:
    def __init__(
        self,
        is_correct: bool,
        issues: List[str],
        parsed_board: Optional[List[List[int]]] = None,
    ) -> None:
        self.is_correct = is_correct
        self.issues = issues
        self.parsed_board = parsed_board


# ----------------------------------------------------------------------
# LLM ä¼šè¯ç®¡ç†
# ----------------------------------------------------------------------
class Sudoku16ChatSession:
    def __init__(
        self,
        puzzle: Sequence[Sequence[int]],
        model: str = "gpt-5",
        temperature: float = 1.0,
        provider: str = "openai",
        history_dir: Optional[Path] = None,
        system_prompt: str = SYSTEM_PROMPT,
    ) -> None:
        self.puzzle = [list(row) for row in puzzle]
        self.model = model
        self.temperature = temperature
        self.provider = provider
        self.session_dir = history_dir or self._default_session_dir()
        self.session_dir.mkdir(parents=True, exist_ok=True)
        self.history_file = self.session_dir / "conversation.json"
        self.system_prompt = system_prompt
        self.provider_config = get_provider(provider)
        self.initial_prompt = USER_PROMPT_TEMPLATE.format(
            puzzle=board_to_display_text(self.puzzle)
        )
        self.messages: List[dict] = []
        self.round_records: List[dict] = []
        self.created_at = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

        # é€šè¿‡å†…éƒ¨æ±‚è§£å™¨éªŒè¯é¢˜ç›®å¯è§£ï¼Œå¹¶è®°å½•ä¸€ä¸ªå‚è€ƒè§£
        solver = Sudoku16Solver(self.puzzle)
        if not solver.solve():
            raise RuntimeError("ç”Ÿæˆçš„ 16x16 æ•°ç‹¬é¢˜ç›®æ— æ³•è¢«å†…éƒ¨æ±‚è§£å™¨è§£å†³ã€‚")
        self.reference_solution = solver.get_solution()

    @staticmethod
    def _default_session_dir() -> Path:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        return Path(__file__).resolve().with_name(f"gpt_sudoku16_session_{timestamp}")

    def _save_history(self) -> None:
        data = {
            "system_prompt": self.system_prompt,
            "puzzle": board_to_display_text(self.puzzle),
            "created_at": self.created_at,
            "rounds": self.round_records,
            "messages": self.messages,
        }
        with self.history_file.open("w", encoding="utf-8") as fh:
            json.dump(data, fh, ensure_ascii=False, indent=2)

    # ------------------------------------------------------------------
    # æ„é€ æç¤º
    # ------------------------------------------------------------------
    def build_initial_prompt(self) -> str:
        return self.initial_prompt

    def build_feedback_prompt(
        self,
        last_answer: str,
        last_issues: Sequence[str],
    ) -> str:
        issues_text = (
            "\n".join(f"- {issue}" for issue in last_issues)
            if last_issues
            else "- æœªæä¾›é—®é¢˜è¯¦æƒ…"
        )
        return FEEDBACK_PROMPT_TEMPLATE.format(
            last_answer=last_answer.strip() or "(ä¸Šä¸€è½®æ²¡æœ‰è¯†åˆ«å‡ºæœ‰æ•ˆç­”æ¡ˆ)",
            issues=issues_text,
            puzzle=board_to_display_text(self.puzzle),
        )

    # ------------------------------------------------------------------
    # ä¸ LLM äº¤äº’
    # ------------------------------------------------------------------
    def request_solution(self, user_content: str) -> Tuple[str, Optional[str], Optional[Dict[str, Any]]]:
        user_message = {"role": "user", "content": user_content}
        messages = [{"role": "system", "content": self.system_prompt}] + self.messages + [user_message]
        assistant_message, reasoning_text, usage = chat_completion(
            provider=self.provider,
            model=self.model,
            messages=messages,
            temperature=self.temperature,
        )

        self.messages.extend(
            [
                user_message,
                {"role": "assistant", "content": assistant_message, "reasoning": reasoning_text},
            ]
        )
        self._save_history()

        return assistant_message, reasoning_text, usage

    # ------------------------------------------------------------------
    # æ ¡éªŒ
    # ------------------------------------------------------------------
    def evaluate_answer(self, raw_answer: str) -> SudokuCheckResult:
        rows = parse_rows_from_text(raw_answer, expected=SIZE)
        if len(rows) < SIZE:
            return SudokuCheckResult(
                is_correct=False,
                issues=["æœªèƒ½è¯†åˆ«å‡ºå®Œæ•´çš„ 16 è¡Œè§£ç­”ï¼Œè¯·ç¡®ä¿è¾“å‡º 16 è¡Œã€æ¯è¡Œ 16 ä¸ªæ•°å­—ã€‚"],
                parsed_board=None,
            )

        candidate = rows[:SIZE]
        issues: List[str] = []

        # çº¿ç´¢ä¸€è‡´æ€§
        for r in range(SIZE):
            for c in range(SIZE):
                clue = self.puzzle[r][c]
                if clue and candidate[r][c] != clue:
                    issues.append(
                        f"åŸé¢˜ç¬¬ {r + 1} è¡Œç¬¬ {c + 1} åˆ—åº”ä¸º {clue}ï¼Œä½†å›ç­”ä¸º {candidate[r][c]}ã€‚"
                    )

        # è¡Œè§„åˆ™
        for idx, row in enumerate(candidate, start=1):
            row_set = set(row)
            if row_set != EXPECTED_SET:
                missing = EXPECTED_SET - row_set
                duplicates = [num for num in row if row.count(num) > 1]
                details = []
                if missing:
                    details.append(f"ç¼ºå°‘ {sorted(missing)}")
                if duplicates:
                    details.append(f"å­˜åœ¨é‡å¤ {sorted(set(duplicates))}")
                issues.append(f"ç¬¬ {idx} è¡Œä¸ç¬¦åˆæ•°ç‹¬è§„åˆ™ï¼š{'; '.join(details)}ã€‚")

        # åˆ—è§„åˆ™
        for col in range(SIZE):
            column = [candidate[row][col] for row in range(SIZE)]
            col_set = set(column)
            if col_set != EXPECTED_SET:
                missing = EXPECTED_SET - col_set
                duplicates = [num for num in column if column.count(num) > 1]
                details = []
                if missing:
                    details.append(f"ç¼ºå°‘ {sorted(missing)}")
                if duplicates:
                    details.append(f"å­˜åœ¨é‡å¤ {sorted(set(duplicates))}")
                issues.append(f"ç¬¬ {col + 1} åˆ—ä¸ç¬¦åˆæ•°ç‹¬è§„åˆ™ï¼š{'; '.join(details)}ã€‚")

        # å®«æ ¼è§„åˆ™
        for box_row in range(BASE):
            for box_col in range(BASE):
                cells = [
                    candidate[r][c]
                    for r in range(box_row * BASE, box_row * BASE + BASE)
                    for c in range(box_col * BASE, box_col * BASE + BASE)
                ]
                cell_set = set(cells)
                if cell_set != EXPECTED_SET:
                    missing = EXPECTED_SET - cell_set
                    duplicates = [num for num in cells if cells.count(num) > 1]
                    details = []
                    if missing:
                        details.append(f"ç¼ºå°‘ {sorted(missing)}")
                    if duplicates:
                        details.append(f"å­˜åœ¨é‡å¤ {sorted(set(duplicates))}")
                    issues.append(
                        f"å®«æ ¼ (è¡Œ {box_row + 1}, åˆ— {box_col + 1}) ä¸ç¬¦åˆæ•°ç‹¬è§„åˆ™ï¼š{'; '.join(details)}ã€‚"
                    )

        is_correct = not issues
        return SudokuCheckResult(is_correct=is_correct, issues=issues, parsed_board=candidate)

    def record_round(
        self,
        round_index: int,
        user_message: str,
        assistant_message: str,
        result: SudokuCheckResult,
        reasoning_log: Optional[str] = None,
    ) -> None:
        record = {
            "round": round_index,
            "user_message": user_message,
            "assistant_message": assistant_message,
            "assistant_reasoning": reasoning_log,
            "validation": {
                "is_correct": result.is_correct,
                "issues": result.issues,
            },
            "parsed_board": board_to_display_text(result.parsed_board)
            if result.parsed_board
            else None,
        }
        self.round_records.append(record)
        self._save_history()


# ----------------------------------------------------------------------
# é¢˜ç›®ç”Ÿæˆ
# ----------------------------------------------------------------------
def generate_random_puzzle(holes: int = 180) -> List[List[int]]:
    rng = random.Random()  # ä½¿ç”¨ç³»ç»Ÿéšæœº
    solution = generate_complete_board(rng)
    puzzle = carve_puzzle(solution, holes=holes, rng=rng)
    return puzzle


# ----------------------------------------------------------------------
# ä¸»æµç¨‹
# ----------------------------------------------------------------------
def run_session(
    model: str,
    temperature: float,
    provider: str,
    reset: bool,
    history_dir: Path,
    holes: int,
    max_rounds: int,
) -> None:
    history_dir = history_dir.resolve()
    history_dir.mkdir(parents=True, exist_ok=True)

    if reset:
        removed = 0
        for path in history_dir.iterdir():
            if path.is_dir():
                shutil.rmtree(path, ignore_errors=True)
                removed += 1
            elif path.is_file():
                try:
                    path.unlink()
                    removed += 1
                except OSError:
                    continue
        print(f"ğŸ§¹ å·²æ¸…ç©º 16x16 å†å²è®°å½•ç›®å½•ï¼Œåˆ é™¤ {removed} ä¸ªå†å²æ¡ç›®ã€‚")

    if holes < 0 or holes > SIZE * SIZE:
        raise ValueError(f"holes å‚æ•°åº”åœ¨ 0~{SIZE * SIZE} èŒƒå›´å†…ã€‚")

    puzzle = generate_random_puzzle(holes=holes)
    session_ts = int(time.time() * 1000)
    session_dir = history_dir / f"session_{session_ts}"

    session = Sudoku16ChatSession(
        puzzle=puzzle,
        model=model,
        temperature=temperature,
        provider=provider,
        history_dir=session_dir,
    )

    print(f"ğŸ“¨ å‘é€ç»™ {provider} çš„ 16x16 é¢˜ç›®ï¼š")
    print(board_to_display_text(puzzle))

    last_answer_text = ""
    last_result: Optional[SudokuCheckResult] = None
    round_count = 0
    final_result: Optional[SudokuCheckResult] = None
    success = False

    for round_index in range(1, max_rounds + 1):
        print(f"\nğŸ” å¼€å§‹ç¬¬ {round_index} è½®å¯¹è¯")

        if round_index == 1:
            user_prompt = session.build_initial_prompt()
        else:
            answer_snapshot = (
                board_to_display_text(last_result.parsed_board)
                if last_result and last_result.parsed_board
                else last_answer_text
            )
            user_prompt = session.build_feedback_prompt(
                last_answer=answer_snapshot,
                last_issues=last_result.issues if last_result else [],
            )

        try:
            assistant_reply, reasoning_log, usage = session.request_solution(user_prompt)
        except LLMClientError as exc:  # pragma: no cover
            print(f"âŒ è°ƒç”¨ {provider} æ¥å£å¤±è´¥ï¼š{exc}")
            return
        except Exception as exc:  # pragma: no cover
            print(f"âŒ è°ƒç”¨ {provider} æ¥å£å‡ºç°æœªçŸ¥é”™è¯¯ï¼š{exc}")
            return

        print(f"\nğŸ¤– {provider} çš„å®Œæ•´å›å¤ï¼š\n")
        print(assistant_reply or "(æœªè¯†åˆ«åˆ°ä»»ä½•å›ç­”å†…å®¹)")

        result = session.evaluate_answer(assistant_reply)
        round_count = round_index
        final_result = result
        session.record_round(
            round_index,
            user_prompt,
            assistant_reply,
            result,
            reasoning_log=reasoning_log,
        )

        if result.is_correct:
            print(f"\nâœ… {provider} åœ¨æœ¬è½®æä¾›äº†æ­£ç¡®çš„ 16x16 æ•°ç‹¬è§£ç­”ã€‚")
            if result.parsed_board:
                print("\nğŸ§¾ æœ€ç»ˆè§£æçš„ 16x16 è§£ç­”ï¼š")
                print(board_to_display_text(result.parsed_board))
            success = True
            break

        print(f"\nâŒ {provider} çš„è§£ç­”ä»å­˜åœ¨é—®é¢˜ï¼š")
        for issue in result.issues:
            print(f"- {issue}")

        if result.parsed_board:
            print("\nğŸ§¾ æœ¬è½®è§£æå‡ºçš„ 16x16 è§£ç­”ï¼š")
            print(board_to_display_text(result.parsed_board))

        last_result = result
        last_answer_text = assistant_reply
    else:
        print(f"\nâš ï¸ å·²è¿›è¡Œ {max_rounds} è½®å¯¹è¯ï¼Œä»æœªè·å¾—æ­£ç¡®è§£ç­”ï¼Œè¯·ç¨åé‡è¯•æˆ–è°ƒæ•´æç¤ºã€‚")

    summary = {
        "model": model,
        "temperature": temperature,
        "provider": provider,
        "timestamp": session.created_at,
        "rounds": round_count,
        "max_rounds": max_rounds,
        "success": success,
        "puzzle": board_to_display_text(puzzle),
        "conversation_file": str(session.history_file.name),
    }
    if final_result:
        summary["final_issues"] = final_result.issues

    summary_path = session.session_dir / "summary.json"
    rounds_path = session.session_dir / "rounds.txt"
    with summary_path.open("w", encoding="utf-8") as fh:
        json.dump(summary, fh, ensure_ascii=False, indent=2)
    rounds_path.write_text(f"{round_count}\n", encoding="utf-8")

    print("\nğŸ“ ä¼šè¯è®°å½•ç›®å½•:", session.session_dir)
    print("   - å¯¹è¯æ–‡ä»¶:", session.history_file)
    print("   - æ¦‚è¦æ–‡ä»¶:", summary_path)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="è°ƒç”¨ LLM è§£ç­” 16x16 æ•°ç‹¬å¹¶éªŒè¯ç»“æœçš„è„šæœ¬")
    parser.add_argument("--model", default="gpt-5", help="è°ƒç”¨çš„æ¨¡å‹åç§°")
    parser.add_argument(
        "--temperature",
        type=float,
        default=1.0,
        help="ç”Ÿæˆæ¸©åº¦ï¼Œé»˜è®¤ä¸º 1.0",
    )
    parser.add_argument(
        "--provider",
        choices=list(PROVIDERS.keys()),
        default="openai",
        help="é€‰æ‹©è°ƒç”¨çš„ LLM ä¾›åº”å•†ï¼ˆopenai/deepseek/qwenï¼‰ï¼Œé»˜è®¤ä¸º openai",
    )
    parser.add_argument(
        "--holes",
        type=int,
        default=180,
        help="æŒ–ç©ºæ•°é‡ï¼ŒèŒƒå›´ 0-256ï¼Œé»˜è®¤ 180ï¼ˆè¾ƒé«˜éš¾åº¦ï¼‰",
    )
    parser.add_argument(
        "--history-dir",
        type=Path,
        default=Path(__file__).resolve().with_name("gpt_sudoku16_histories"),
        help="ä¿å­˜ 16x16 ä¼šè¯è®°å½•çš„ç›®å½•ï¼Œé»˜è®¤ä¸è„šæœ¬åŒçº§çš„ gpt_sudoku16_histories",
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help="åœ¨æŸ¥è¯¢å‰æ¸…é™¤å†å²å¯¹è¯è®°å½•ç›®å½•",
    )
    parser.add_argument(
        "--max-rounds",
        type=int,
        default=10,
        help="å…è®¸ä¸æ¨¡å‹è¿›è¡Œçš„æœ€å¤§è½®æ•°ï¼Œé»˜è®¤ä¸º 10",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    run_session(
        model=args.model,
        temperature=args.temperature,
        provider=args.provider,
        reset=args.reset,
        history_dir=args.history_dir,
        holes=args.holes,
        max_rounds=max(args.max_rounds, 1),
    )

