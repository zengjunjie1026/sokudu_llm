"""è°ƒç”¨ LLMï¼ˆOpenAI/DeepSeek/Qwen ç­‰ï¼‰è§£ç­” 9x9 æ•°ç‹¬é¢˜ç›®çš„è„šæœ¬ã€‚

è¯¥è„šæœ¬ä¼šï¼š
- æ„é€ é™åˆ¶æ¨¡å‹ä¸èƒ½è°ƒç”¨ä»»ä½•å·¥å…·çš„æç¤ºè¯
- å°†ä¹‹å‰çš„æç¤ºè¯ä¸å›å¤ä½œä¸ºä¸Šä¸‹æ–‡ç»§ç»­å¯¹è¯
- è°ƒç”¨ LLM è·å–æ•°ç‹¬è§£ç­”
- è§£æå¹¶æ ¡éªŒè§£ç­”çš„æ­£ç¡®æ€§ï¼Œåé¦ˆé—®é¢˜
"""

from __future__ import annotations

import argparse
import json
import random
import re
import shutil
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Tuple

from sudoku_solver import SudokuSolver

from llm_client import LLMClientError, PROVIDERS, chat_completion, get_provider


SYSTEM_PROMPT = (
    "You are a reasoning-only assistant working in a plain text environment. "
    "You must not invoke, simulate, or reference any external tools, code execution, "
    "or calculators. Solve the Sudoku puzzle strictly by mental reasoning and provide "
    "your final answer clearly."
)

USER_PROMPT_TEMPLATE = (
     """You are a reasoning-only assistant operating in a plain text environment. Your task is to solve the given Sudoku puzzle using logical deduction onlyâ€”no guessing, no external tools, and no reliance on precomputed solutions.

Instructions:
1. The puzzle is a {size}Ã—{size} grid, where {size} is typically 9 (standard Sudoku), but may vary (e.g., 4 or 6).
2. Each row, each column, and each designated subgrid (box) must contain all digits from 1 to {size} exactly once.
3. Empty cells in the puzzle are represented by '0' or '.' â€” treat them as unknowns to be filled.
4. Use step-by-step deductive reasoning to determine the correct digit for each empty cell.
5. Do not output any explanations, comments, thought processes, or formatting beyond the final answer.
6. Return exactly {size} lines of output.
7. Each line must contain exactly {size} digits (from 1 to {size}), separated by single spaces.
8. Ensure the completed grid satisfies all Sudoku rules.

Puzzle Input Format:
- The puzzle is provided below under "Puzzle:".
- Each line represents a row of the grid.
- Digits are separated by spaces; empty cells are marked as '0' or '.'.

Your Output Format:
- Only the solved grid.
- {size} lines.
- Each line: {size} numbers separated by single spaces.
- No extra text before or after.

Now solve the following Sudoku puzzle:

Puzzle:
{puzzle}"""
   
)

FEEDBACK_PROMPT_TEMPLATE = """Your previous solutions are still incorrect. Review every past attempt and fix all listed issues.

Instructions (apply to a {size}Ã—{size} Sudoku grid):
1. You must NOT use or mention any external tools, code, or solversâ€”only mental reasoning.
2. Produce exactly {size} lines of output; each line must contain {size} digits (1â€“{size}) separated by single spaces.
3. Do not add commentary before or after the grid. If you need to explain, do it only after the grid on a new paragraph.
4. Every row, column, and subgrid must satisfy Sudoku rules and must respect the givens from the puzzle.
5. Address every issue listed below before submitting a new answer.

History of answers and detected problems:
{history}

Puzzle (repeated for convenience):
{puzzle}
"""

def board_to_text(board: Sequence[Sequence[int]]) -> str:
    """å°† 9x9 æ•°ç‹¬æ£‹ç›˜è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤ºï¼Œç©ºæ ¼ä½¿ç”¨å¥ç‚¹è¡¨ç¤ºã€‚"""

    lines: List[str] = []
    for row in board:
        line = " ".join(str(value) if value else "." for value in row)
        lines.append(line)
    return "\n".join(lines)


def slice_rows_with_digits(text: str, expected: int = 9) -> List[List[int]]:
    """ä»æ¨¡å‹å›å¤ä¸­æˆªå–åŒ…å« 9 ä¸ªæ•°å­—çš„è¡Œã€‚"""

    rows: List[List[int]] = []
    for line in text.splitlines():
        digits = [int(ch) for ch in re.findall(r"[0-9]", line)]
        if len(digits) == expected:
            rows.append(digits)
    return rows


def first_mismatch(
    board_a: Sequence[Sequence[int]],
    board_b: Sequence[Sequence[int]],
) -> Optional[Tuple[int, int]]:
    """è¿”å›ä¸¤ä¸ªæ£‹ç›˜ç¬¬ä¸€ä¸ªä¸åŒçš„åæ ‡ã€‚"""

    for r in range(9):
        for c in range(9):
            if board_a[r][c] != board_b[r][c]:
                return r, c
    return None


@dataclass
class SudokuCheckResult:
    """å°è£…æ ¡éªŒç»“æœã€‚"""

    is_correct: bool
    issues: List[str]
    parsed_board: Optional[List[List[int]]] = None


class SudokuChatSession:
    """ä¸ LLM è¿›è¡Œæ•°ç‹¬å¯¹è¯çš„ä¼šè¯ç®¡ç†å™¨ã€‚"""

    def __init__(
        self,
        puzzle: Sequence[Sequence[int]],
        model: str = "gpt-5",
        temperature: float = 1,
        provider: str = "openai",
        history_dir: Optional[Path] = None,
        system_prompt: str = SYSTEM_PROMPT,
    ) -> None:
        self.puzzle = [list(row) for row in puzzle]
        self.model = model
        self.temperature = temperature
        self.provider = provider
        self.session_dir = history_dir or self._default_session_dir()
        self.session_dir.mkdir(parents=True, exist_ok=True)
        self.history_file = self.session_dir / "conversation.json"
        self.system_prompt = system_prompt
        self.provider_config = get_provider(provider)
        self.correct_solution = self._solve_baseline()
        self.initial_prompt = USER_PROMPT_TEMPLATE.format(
            puzzle=board_to_text(self.puzzle),
            size=len(self.puzzle),
        )
        self.messages: List[dict] = []
        self.round_records: List[dict] = []
        self.created_at = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
        self.prompt_tokens = 0
        self.completion_tokens = 0

    @staticmethod
    def _default_session_dir() -> Path:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        return Path(__file__).resolve().with_name(f"gpt_sudoku_session_{timestamp}")

    def _save_history(self) -> None:
        data = {
            "system_prompt": self.system_prompt,
            "puzzle": board_to_text(self.puzzle),
            "created_at": self.created_at,
            "rounds": self.round_records,
            "messages": self.messages,
        }
        with self.history_file.open("w", encoding="utf-8") as fh:
            json.dump(data, fh, ensure_ascii=False, indent=2)

    # ------------------------------------------------------------------
    # ä¸šåŠ¡é€»è¾‘
    # ------------------------------------------------------------------
    def _solve_baseline(self) -> List[List[int]]:
        solver = SudokuSolver(self.puzzle)
        if not solver.solve():
            raise RuntimeError("ç¤ºä¾‹æ•°ç‹¬æ— æ³•è¢«å†…éƒ¨æ±‚è§£å™¨è§£å†³ï¼Œè¯·æ£€æŸ¥é¢˜ç›®æ•°æ®ã€‚")
        return solver.get_solution()

    def build_initial_prompt(self) -> str:
        return self.initial_prompt

    def build_feedback_prompt(
        self,
        history: Sequence[Tuple[str, Sequence[str]]],
    ) -> str:
        sections: List[str] = []
        for idx, (answer, issues) in enumerate(history, start=1):
            cleaned_answer = answer.strip() or "(æœªè¯†åˆ«åˆ°æœ‰æ•ˆç­”æ¡ˆ)"
            if issues:
                issues_text = "\n".join(f"    - {issue}" for issue in issues)
            else:
                issues_text = "    - æœªæä¾›é—®é¢˜è¯¦æƒ…"
            sections.append(
                f"å›ç­” {idx}ï¼š\n{cleaned_answer}\nå­˜åœ¨çš„é—®é¢˜ï¼š\n{issues_text}"
            )

        history_text = "\n\n".join(sections) if sections else "(æš‚æ— å†å²è®°å½•)"
        return FEEDBACK_PROMPT_TEMPLATE.format(
            size=len(self.puzzle),
            history=history_text,
            puzzle=board_to_text(self.puzzle),
        )

    def request_solution(self, user_content: str) -> Tuple[str, Optional[str], Optional[Dict[str, Any]]]:
        """å‘ LLM å‘é€è¯·æ±‚å¹¶è¿”å›æ–‡æœ¬å›å¤ã€‚"""

        user_message = {"role": "user", "content": user_content}
        messages = [{"role": "system", "content": self.system_prompt}] + self.messages + [user_message]

        assistant_message, reasoning_text, usage = chat_completion(
            provider=self.provider,
            model=self.model,
            messages=messages,
            temperature=self.temperature,
        )

        # æ›´æ–°å†å²
        assistant_entry = {"role": "assistant", "content": assistant_message}
        if reasoning_text:
            assistant_entry["reasoning"] = reasoning_text
        self.messages.extend([user_message, assistant_entry])
        self._save_history()

        if usage:
            prompt_tokens = usage.get("prompt_tokens")
            completion_tokens = usage.get("completion_tokens")
            if isinstance(prompt_tokens, int):
                self.prompt_tokens += prompt_tokens
            if isinstance(completion_tokens, int):
                self.completion_tokens += completion_tokens

        return assistant_message, reasoning_text, usage

    # ------------------------------------------------------------------
    # æ ¡éªŒé€»è¾‘
    # ------------------------------------------------------------------
    def evaluate_answer(self, raw_answer: str) -> SudokuCheckResult:
        rows = slice_rows_with_digits(raw_answer)
        if len(rows) < 9:
            return SudokuCheckResult(
                is_correct=False,
                issues=[
                    "Failed to detect 9 valid lines. Please output 9 lines, each containing exactly 9 digits."
                ],
                parsed_board=None,
            )

        candidate = rows[:9]
        issues: List[str] = []

        # é•¿åº¦ä¸èŒƒå›´æ£€æŸ¥
        for r_idx, row in enumerate(candidate, start=1):
            if len(row) != 9:
                issues.append(f"Row {r_idx} does not contain exactly 9 digits.")
            out_of_range = [num for num in row if num < 1 or num > 9]
            if out_of_range:
                issues.append(f"Row {r_idx} contains digits outside 1-9: {sorted(out_of_range)}.")

        # çº¿ç´¢ä¸€è‡´æ€§
        for r in range(9):
            for c in range(9):
                clue = self.puzzle[r][c]
                if clue and candidate[r][c] != clue:
                    issues.append(
                        f"Cell ({r + 1}, {c + 1}) must be {clue} per the puzzle, but your answer uses {candidate[r][c]}."
                    )

        # è¡Œã€åˆ—ã€å®«æ ¼æ£€æµ‹
        expected_set = set(range(1, 10))

        for idx, row in enumerate(candidate, start=1):
            row_set = set(row)
            if row_set != expected_set:
                missing = expected_set - row_set
                duplicates = [num for num in row if row.count(num) > 1]
                issue_parts = []
                if missing:
                    issue_parts.append(f"missing {sorted(missing)}")
                if duplicates:
                    issue_parts.append(f"duplicate {sorted(set(duplicates))}")
                issues.append(f"Row {idx} violates Sudoku rules: {'; '.join(issue_parts)}.")

        for col in range(9):
            column = [candidate[row][col] for row in range(9)]
            col_set = set(column)
            if col_set != expected_set:
                missing = expected_set - col_set
                duplicates = [num for num in column if column.count(num) > 1]
                issue_parts = []
                if missing:
                    issue_parts.append(f"missing {sorted(missing)}")
                if duplicates:
                    issue_parts.append(f"duplicate {sorted(set(duplicates))}")
                issues.append(f"Column {col + 1} violates Sudoku rules: {'; '.join(issue_parts)}.")

        for box_row in range(3):
            for box_col in range(3):
                cells = [
                    candidate[r][c]
                    for r in range(box_row * 3, box_row * 3 + 3)
                    for c in range(box_col * 3, box_col * 3 + 3)
                ]
                cell_set = set(cells)
                if cell_set != expected_set:
                    missing = expected_set - cell_set
                    duplicates = [num for num in cells if cells.count(num) > 1]
                    issue_parts = []
                    if missing:
                            issue_parts.append(f"missing {sorted(missing)}")
                    if duplicates:
                            issue_parts.append(f"duplicate {sorted(set(duplicates))}")
                    issues.append(
                            f"Subgrid ({box_row + 1}, {box_col + 1}) violates Sudoku rules: {'; '.join(issue_parts)}."
                    )

        is_correct = not issues
        return SudokuCheckResult(is_correct=is_correct, issues=issues, parsed_board=candidate)

    def record_round(
        self,
        round_index: int,
        user_message: str,
        assistant_message: str,
        result: SudokuCheckResult,
        reasoning_log: Optional[str] = None,
        token_usage: Optional[Dict[str, Any]] = None,
    ) -> None:
        record = {
            "round": round_index,
            "user_message": user_message,
            "assistant_message": assistant_message,
            "assistant_reasoning": reasoning_log,
            "validation": {
                "is_correct": result.is_correct,
                "issues": result.issues,
            },
            "parsed_board": board_to_text(result.parsed_board) if result.parsed_board else None,
        }
        if token_usage:
            record["token_usage"] = token_usage
        self.round_records.append(record)
        self._save_history()


def pattern(base: int, row: int, col: int) -> int:
    side = base * base
    return (base * (row % base) + row // base + col) % side


def shuffled(sequence):
    seq = list(sequence)
    random.shuffle(seq)
    return seq


def generate_complete_board(base: int = 3) -> List[List[int]]:
    side = base * base
    rows = [g * base + r for g in shuffled(range(base)) for r in shuffled(range(base))]
    cols = [g * base + c for g in shuffled(range(base)) for c in shuffled(range(base))]
    nums = shuffled(range(1, side + 1))
    return [[nums[pattern(base, r, c)] for c in cols] for r in rows]


def carve_puzzle(board: Sequence[Sequence[int]], holes: int) -> List[List[int]]:
    puzzle = [row[:] for row in board]
    cells = [(r, c) for r in range(9) for c in range(9)]
    random.shuffle(cells)
    for r, c in cells[:holes]:
        puzzle[r][c] = 0
    return puzzle


def generate_random_puzzle(holes: int = 45) -> List[List[int]]:
    holes = max(0, min(81, holes))
    full_board = generate_complete_board()
    return carve_puzzle(full_board, holes)


def run_session(
    model: str,
    temperature: float,
    provider: str,
    reset: bool,
    history_dir: Path,
    holes: int,
    max_rounds: int,
    puzzle_override: Optional[Sequence[Sequence[int]]] = None,
    session_dir_override: Optional[Path] = None,
) -> Dict[str, Any]:
    history_dir = history_dir.resolve()
    history_dir.mkdir(parents=True, exist_ok=True)

    if reset:
        removed = 0
        for path in history_dir.iterdir():
            if path.is_dir():
                shutil.rmtree(path, ignore_errors=True)
                removed += 1
            elif path.is_file():
                try:
                    path.unlink()
                    removed += 1
                except OSError:
                    continue
        print(f"ğŸ§¹ å·²æ¸…ç©ºå†å²è®°å½•ç›®å½•ï¼Œåˆ é™¤ {removed} ä¸ªå†å²æ¡ç›®ã€‚")

    if puzzle_override is not None:
        puzzle = [list(row) for row in puzzle_override]
    else:
        puzzle = generate_random_puzzle(holes=holes)
    session_ts = int(time.time() * 1000)
    if session_dir_override is not None:
        session_dir = session_dir_override.resolve()
        session_dir.mkdir(parents=True, exist_ok=True)
    else:
        session_dir = history_dir / f"session_{session_ts}"
        session_dir.mkdir(parents=True, exist_ok=True)

    session = SudokuChatSession(
        puzzle=puzzle,
        model=model,
        temperature=temperature,
        provider=provider,
        history_dir=session_dir,
    )

    print(f"ğŸ“¨ å‘é€ç»™ {provider} çš„é¢˜ç›®ï¼š")
    print(board_to_text(puzzle))

    last_answer_text = ""
    last_result: Optional[SudokuCheckResult] = None
    attempt_history: List[Tuple[str, List[str]]] = []
    round_count = 0
    final_result: Optional[SudokuCheckResult] = None
    success = False

    for round_index in range(1, max_rounds + 1):
        print(f"\nğŸ” å¼€å§‹ç¬¬ {round_index} è½®å¯¹è¯")

        if round_index == 1:
            user_prompt = session.build_initial_prompt()
        else:
            answer_snapshot = (
                board_to_text(last_result.parsed_board)
                if last_result and last_result.parsed_board
                else last_answer_text
            )
            user_prompt = session.build_feedback_prompt(history=attempt_history)

        try:
            assistant_reply, reasoning_log, usage = session.request_solution(user_prompt)
        except LLMClientError as exc:  # pragma: no cover - è¿è¡ŒæœŸå®¹é”™
            print(f"âŒ è°ƒç”¨ {provider} æ¥å£å¤±è´¥ï¼š{exc}")
            return {
                "model": model,
                "temperature": temperature,
                "provider": provider,
                "timestamp": session.created_at,
                "rounds": round_count,
                "max_rounds": max_rounds,
                "success": False,
                "puzzle": board_to_text(puzzle),
                "conversation_file": str(session.history_file.name),
                "error": str(exc),
            }
        except Exception as exc:  # pragma: no cover - è¿è¡ŒæœŸå®¹é”™
            print(f"âŒ è°ƒç”¨ {provider} æ¥å£å‡ºç°æœªçŸ¥é”™è¯¯ï¼š{exc}")
            return {
                "model": model,
                "temperature": temperature,
                "provider": provider,
                "timestamp": session.created_at,
                "rounds": round_count,
                "max_rounds": max_rounds,
                "success": False,
                "puzzle": board_to_text(puzzle),
                "conversation_file": str(session.history_file.name),
                "error": str(exc),
            }

        print(f"\nğŸ¤– {provider} çš„å®Œæ•´å›å¤ï¼š\n")
        print(assistant_reply or "(æœªè¯†åˆ«åˆ°ä»»ä½•å›ç­”å†…å®¹)")

        result = session.evaluate_answer(assistant_reply)
        round_count = round_index
        final_result = result
        session.record_round(
            round_index,
            user_prompt,
            assistant_reply,
            result,
            reasoning_log=reasoning_log,
            token_usage=usage,
        )

        if result.is_correct:
            print(f"\nâœ… {provider} åœ¨æœ¬è½®æä¾›äº†æ­£ç¡®çš„æ•°ç‹¬è§£ç­”ã€‚")
            if result.parsed_board:
                print("\nğŸ§¾ æœ€ç»ˆè§£æçš„ 9x9 è§£ç­”ï¼š")
                print(board_to_text(result.parsed_board))
            success = True
            break

        print(f"\nâŒ {provider} çš„è§£ç­”ä»å­˜åœ¨é—®é¢˜ï¼š")
        for issue in result.issues:
            print(f"- {issue}")

        if result.parsed_board:
            print("\nğŸ§¾ æœ¬è½®è§£æå‡ºçš„ 9x9 è§£ç­”ï¼š")
            print(board_to_text(result.parsed_board))

        last_result = result
        last_answer_text = assistant_reply
        attempt_history.append(
            (
                assistant_reply.strip()
                or (board_to_text(result.parsed_board) if result.parsed_board else "(æœªè¯†åˆ«åˆ°æœ‰æ•ˆç­”æ¡ˆ)"),
                list(result.issues),
            )
        )
    else:
        print(f"\nâš ï¸ å·²è¿›è¡Œ {max_rounds} è½®å¯¹è¯ï¼Œä»æœªè·å¾—æ­£ç¡®è§£ç­”ï¼Œè¯·ç¨åé‡è¯•æˆ–è°ƒæ•´æç¤ºã€‚")

    summary = {
        "model": model,
        "temperature": temperature,
        "provider": provider,
        "timestamp": session.created_at,
        "rounds": round_count,
        "max_rounds": max_rounds,
        "success": success,
        "puzzle": board_to_text(puzzle),
        "conversation_file": str(session.history_file.name),
        "error": None,
        "token_usage": {
            "prompt_tokens": session.prompt_tokens,
            "completion_tokens": session.completion_tokens,
            "total_tokens": session.prompt_tokens + session.completion_tokens,
        },
    }
    if final_result:
        summary["final_issues"] = final_result.issues

    summary_path = session.session_dir / "summary.json"
    rounds_path = session.session_dir / "rounds.txt"
    with summary_path.open("w", encoding="utf-8") as fh:
        json.dump(summary, fh, ensure_ascii=False, indent=2)
    rounds_path.write_text(f"{round_count}\n", encoding="utf-8")

    print("\nğŸ“ ä¼šè¯è®°å½•ç›®å½•:", session.session_dir)
    print("   - å¯¹è¯æ–‡ä»¶:", session.history_file)
    print("   - æ¦‚è¦æ–‡ä»¶:", summary_path)

    return summary


def load_dataset_puzzles(dataset_path: Path) -> List[List[List[int]]]:
    dataset_path = dataset_path.resolve()
    with dataset_path.open("r", encoding="utf-8") as fh:
        payload = json.load(fh)

    puzzles = payload.get("puzzles")
    if not isinstance(puzzles, list):
        raise ValueError("æ•°æ®é›†ç¼ºå°‘ puzzles åˆ—è¡¨ã€‚")

    extracted: List[List[List[int]]] = []
    for entry in puzzles:
        puzzle = entry.get("puzzle")
        if not isinstance(puzzle, list):
            continue
        extracted.append(puzzle)
    return extracted


def run_dataset_benchmark(
    dataset_path: Path,
    limit: int,
    model: str,
    temperature: float,
    provider: str,
    reset: bool,
    history_dir: Path,
    max_rounds: int,
    retry_attempts: int,
) -> None:
    puzzles = load_dataset_puzzles(dataset_path)
    limit = max(0, min(limit, len(puzzles)))
    if limit == 0:
        print(f"âš ï¸ æ•°æ®é›†ä¸ºç©ºæˆ– limit=0ï¼š{dataset_path}")
        return

    dataset_history_root = history_dir.resolve() / f"dataset_run_{time.strftime('%Y%m%d_%H%M%S')}"
    dataset_history_root.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ æ•°æ®é›†æ—¥å¿—ç›®å½•: {dataset_history_root}")

    print(
        f"ğŸ“š ä½¿ç”¨æ•°æ®é›† {dataset_path} çš„å‰ {limit} é“é¢˜ï¼Œè¯„ä¼°æ¨¡å‹ {provider}:{model} "
        f"(temperature={temperature}, max_rounds={max_rounds})"
    )

    success_count = 0
    total_rounds = 0
    per_puzzle_rounds: List[int] = []
    per_puzzle_success: List[bool] = []
    skipped_puzzles: List[Dict[str, Any]] = []

    for idx in range(limit):
        print(f"\n=== æ•°æ®é›†é¢˜ç›® {idx + 1}/{limit} ===")
        summary: Optional[Dict[str, Any]] = None
        last_error: Optional[str] = None

        for attempt in range(1, max(1, retry_attempts) + 1):
            attempt_dir = dataset_history_root / f"puzzle_{idx + 1:04d}" / f"attempt_{attempt:02d}"
            summary = run_session(
                model=model,
                temperature=temperature,
            provider=provider,
            reset=reset and idx == 0 and attempt == 1,
                history_dir=history_dir,
                holes=0,
                max_rounds=max_rounds,
                puzzle_override=puzzles[idx],
                session_dir_override=attempt_dir,
            )
            if summary is None:
                last_error = "unknown failure"
                print(
                    f"âš ï¸ é¢˜ç›® {idx + 1} ç¬¬ {attempt}/{retry_attempts} æ¬¡å°è¯•å¤±è´¥ï¼šæœªçŸ¥åŸå› "
                )
                time.sleep(1)
                continue
            if summary.get("error"):
                last_error = summary["error"]
                print(
                    f"âš ï¸ é¢˜ç›® {idx + 1} ç¬¬ {attempt}/{retry_attempts} æ¬¡å°è¯•å¤±è´¥ï¼š{last_error}"
                )
                time.sleep(1)
                continue
            break

        if summary is None or summary.get("error"):
            print(f"ğŸš« é¢˜ç›® {idx + 1} å¤šæ¬¡é‡è¯•å¤±è´¥ï¼Œè·³è¿‡ã€‚")
            skipped_puzzles.append(
                {
                    "index": idx,
                    "error": last_error or "unknown failure",
                    "attempts": retry_attempts,
                }
            )
            per_puzzle_success.append(False)
            per_puzzle_rounds.append(0)
            continue

        per_puzzle_success.append(summary.get("success", False))
        per_puzzle_rounds.append(summary.get("rounds", max_rounds))
        if summary.get("success"):
            success_count += 1
            total_rounds += summary.get("rounds", 0)

    print("\n=== æ•°æ®é›†è¯„ä¼°æ€»ç»“ ===")
    success_rate = success_count / limit
    avg_rounds = total_rounds / success_count if success_count else None
    print(f"æ€»é¢˜ç›®æ•°: {limit}")
    print(f"æˆåŠŸé¢˜ç›®æ•°: {success_count} ({success_rate:.1%})")
    if avg_rounds is not None:
        print(f"å¹³å‡æˆåŠŸè½®æ•°: {avg_rounds:.2f}")
    else:
        print("å¹³å‡æˆåŠŸè½®æ•°: æ— æˆåŠŸé¢˜ç›®")

    if skipped_puzzles:
        skipped_path = history_dir.resolve() / "dataset_skipped.json"
        record = {
            "dataset": str(dataset_path),
            "model": model,
            "provider": provider,
            "temperature": temperature,
            "max_rounds": max_rounds,
            "retry_attempts": retry_attempts,
            "failed_puzzles": skipped_puzzles,
        }
        with skipped_path.open("w", encoding="utf-8") as fh:
            json.dump(record, fh, ensure_ascii=False, indent=2)
        print(f"âš ï¸ æœ‰ {len(skipped_puzzles)} é“é¢˜æœªå®Œæˆï¼Œå·²è®°å½•åœ¨ {skipped_path}")
    else:
        print("æ‰€æœ‰é¢˜ç›®å‡å·²å°è¯•å®Œæˆã€‚")


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="è°ƒç”¨ LLM è§£ç­”æ•°ç‹¬å¹¶éªŒè¯ç»“æœçš„è„šæœ¬")
    parser.add_argument(
        "--model",
        default=None,
        help="è°ƒç”¨çš„æ¨¡å‹åç§°ï¼›é»˜è®¤ä¸ºæ‰€é€‰ provider çš„é»˜è®¤æ¨¡å‹",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=1,
        help="ç”Ÿæˆæ¸©åº¦ï¼Œé»˜è®¤ä¸º 1",
    )
    parser.add_argument(
        "--provider",
        choices=list(PROVIDERS.keys()),
        default="openai",
        help="é€‰æ‹©è°ƒç”¨çš„ LLM ä¾›åº”å•†ï¼ˆopenai/deepseek/qwenï¼‰ï¼Œé»˜è®¤ä¸º openai",
    )
    parser.add_argument(
        "--reset",
        action="store_true",
        help="åœ¨æŸ¥è¯¢å‰æ¸…é™¤å†å²å¯¹è¯è®°å½•",
    )
    parser.add_argument(
        "--history-dir",
        type=Path,
        default=Path(__file__).resolve().with_name("gpt_sudoku_histories"),
        help="ä¿å­˜ä¼šè¯è®°å½•çš„ç›®å½•ï¼Œé»˜è®¤ä¸è„šæœ¬åŒçº§çš„ gpt_sudoku_histories",
    )
    parser.add_argument(
        "--holes",
        type=int,
        default=45,
        help="ç§»é™¤çš„æ ¼å­æ•°é‡ï¼ŒèŒƒå›´ 0-81ï¼Œé»˜è®¤ä¸º 45 (ä¸­ç­‰éš¾åº¦)",
    )
    parser.add_argument(
        "--max-rounds",
        type=int,
        default=10,
        help="å…è®¸ä¸æ¨¡å‹è¿›è¡Œçš„æœ€å¤§è½®æ•°ï¼Œé»˜è®¤ä¸º 10",
    )
    parser.add_argument(
        "--dataset",
        type=Path,
        default=None,
        help="æŒ‡å®šæ•°æ®é›† JSONï¼ˆå¦‚ sokudu_dataset/sudoku_9x9.jsonï¼‰æ—¶ï¼Œå°†æŒ‰é¡ºåºä½¿ç”¨é¢˜ç›®ï¼Œè€Œééšæœºç”Ÿæˆã€‚",
    )
    parser.add_argument(
        "--dataset-limit",
        type=int,
        default=100,
        help="ä½¿ç”¨æ•°æ®é›†æ¨¡å¼æ—¶ï¼Œè¯»å–çš„é¢˜ç›®æ•°é‡ï¼ˆé»˜è®¤ 100ï¼‰ã€‚",
    )
    parser.add_argument(
        "--retry-attempts",
        type=int,
        default=10,
        help="è°ƒç”¨å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 10 æ¬¡ï¼‰ã€‚",
    )
    parser.add_argument(
        "--use-ollama",
        action="store_true",
        help="å¿«æ·æ–¹å¼ï¼šä½¿ç”¨æœ¬åœ° ollama æä¾›çš„ gpt-oss æ¨¡å‹ï¼ˆå°† provider è®¾ç½®ä¸º ollamaï¼‰ã€‚",
    )

    args = parser.parse_args()
    if args.use_ollama:
        args.provider = "ollama"
        if args.model is None:
            args.model = "gpt-oss:20b"

    if args.model is None:
        args.model = PROVIDERS[args.provider].default_model

    return args


if __name__ == "__main__":
    args = parse_args()
    effective_temp = (
        1.0 if args.provider == "openai" and args.model.lower().startswith("gpt-5") else args.temperature
    )
    if args.dataset:
        run_dataset_benchmark(
            dataset_path=args.dataset,
            limit=args.dataset_limit,
            model=args.model,
            temperature=effective_temp,
            provider=args.provider,
            reset=args.reset,
            history_dir=args.history_dir,
            max_rounds=max(args.max_rounds, 1),
            retry_attempts=max(1, args.retry_attempts),
        )
    else:
        run_session(
            model=args.model,
            temperature=effective_temp,
            provider=args.provider,
            reset=args.reset,
            history_dir=args.history_dir,
            holes=args.holes,
            max_rounds=max(args.max_rounds, 1),
        )
